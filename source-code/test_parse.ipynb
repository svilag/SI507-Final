{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import datetime as dt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "URLS = \"./urls.json\"\n",
    "CACHE = {}\n",
    "CACHE_PATH = './cache/cache.json'\n",
    "\n",
    "# Classes\n",
    "\n",
    "@dataclass()\n",
    "class Group:\n",
    "    \"\"\"creates a group class object\"\"\"\n",
    "    name: str\n",
    "    class_level: str\n",
    "    location: str\n",
    "    competitions: dict\n",
    "\n",
    "    def jsonify(self):\n",
    "        \"\"\"returns class object as json\"\"\"\n",
    "        group_json = {\n",
    "            \"name\": self.name,\n",
    "            \"class_level\": self.class_level,\n",
    "            \"location\": self.location,\n",
    "            \"competitions\": self.competitions\n",
    "        }\n",
    "        return group_json\n",
    "\n",
    "@dataclass()\n",
    "class Competition:\n",
    "    \"\"\"creates a competition class object\"\"\"\n",
    "    title: str\n",
    "    date: str\n",
    "    scores: str\n",
    "    recap: str\n",
    "    groups: list\n",
    "    scores_by_group: dict\n",
    "\n",
    "    def jsonify(self):\n",
    "        \"\"\"returns class object as json\"\"\"\n",
    "        comp_json = {\n",
    "            \"title\": self.title,\n",
    "            \"date\": self.date,\n",
    "            \"scores\": self.scores,\n",
    "            \"recap\": self.recap,\n",
    "            \"groups\": [group.name for group in self.groups],\n",
    "            \"scores_by_group\": self.scores_by_group\n",
    "        }\n",
    "        return comp_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filepath:str, encoding='utf-8') -> dict:\n",
    "    \"\"\"Reads a json file and returns a dictionary of the object\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding=encoding) as file_obj:\n",
    "        return json.load(file_obj)\n",
    "\n",
    "def write_json(filepath:str, data, encoding='utf-8', ensure_ascii=False, indent=4):\n",
    "    \"\"\" Serializes object as JSON. Writes content to the provided filepath.\n",
    "        Appends to the end of the file. Checks if filepath exists.\n",
    "        If not, appends file creating a new one if the file does not exists,\n",
    "        else writes over the file. If add=True, appends to the end of the file.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str): the path to the file\n",
    "        data (dict)/(list): the data to be encoded as JSON and written to the file\n",
    "        encoding (str): name of encoding used to encode the file\n",
    "        ensure_ascii (str): if False non-ASCII characters are printed as is; otherwise\n",
    "                            non-ASCII characters are escaped.\n",
    "        indent (int): number of \"pretty printed\" indention spaces applied to encoded JSON\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        with open(filepath, 'a', encoding=encoding) as file_obj:\n",
    "            json.dump(data, file_obj, ensure_ascii=ensure_ascii, indent=indent)\n",
    "    else:\n",
    "        with open(filepath, 'w', encoding=encoding) as file_obj:\n",
    "            json.dump(data, file_obj, ensure_ascii=ensure_ascii, indent=indent)\n",
    "\n",
    "def get_content(url:str) -> str:\n",
    "    \"\"\"Takes a url and returns the html content\n",
    "\n",
    "    params:\n",
    "        url(string): link to html content\n",
    "\n",
    "    returns:\n",
    "        response.text: html content\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    # logger.info(\"Fetching content from %s...\", url)\n",
    "\n",
    "    return response.text\n",
    "\n",
    "def read_cache() -> dict:\n",
    "    \"\"\" reads the cache file\n",
    "        returns the cache\n",
    "    \"\"\"\n",
    "    cache = read_json(CACHE_PATH)\n",
    "    # logger.info(\"Reading from cache...\")\n",
    "    return cache\n",
    "\n",
    "\n",
    "def check_cache(url:str) -> str:\n",
    "    \"\"\" checks cache for url.\n",
    "        if url not in cache, adds it and rewrites the cache.\n",
    "        returns html content\n",
    "    \"\"\"\n",
    "    cache = read_cache()\n",
    "    if url not in cache.keys():\n",
    "        cache[url] = get_content(url)\n",
    "        write_json(CACHE_PATH, cache)\n",
    "    #     logger.info(\"Writing %s to cache...\", url)\n",
    "    # logger.info(\"Fetching %s from cache...\", url)\n",
    "    return cache[url]\n",
    "\n",
    "\n",
    "def get_competitions(url):\n",
    "    \"\"\"gets competition data\n",
    "    \"\"\"\n",
    "    html_data = check_cache(url)\n",
    "\n",
    "    soup = bs(html_data, 'html.parser')\n",
    "    # logger.info(\"Parsing page: %s\", url)\n",
    "\n",
    "    table_rows = soup.find_all('tr') # list of table rows\n",
    "\n",
    "    comps = []\n",
    "\n",
    "    for t_r in table_rows[:-1]:\n",
    "        tr_children = [child for child in t_r.children] # find children\n",
    "        if len(tr_children) == 3: # rows with dates\n",
    "            year = re.search(\"20..\", url).group()\n",
    "            date = f\"{tr_children[1:-1:1][0].strong.contents[0]}, {year}\" # month day, year\n",
    "        elif len(tr_children) == 9: # rows with groups and scores\n",
    "            tr_children_data = tr_children[1::2][1:]\n",
    "            comp_name = tr_children_data[0].contents[0] # get competition name # list\n",
    "\n",
    "            # check if there is a link to scores # some don't have scores\n",
    "            if tr_children_data[1].a:\n",
    "                scores = tr_children_data[1].a['href'] # get link to scores\n",
    "            else:\n",
    "                scores = \"No scores\"\n",
    "                # logger.info(\"No scores found for %s\", comp_name)\n",
    "\n",
    "            # check if there is a link to recaps # some don't have recaps\n",
    "            if tr_children_data[-1].a:\n",
    "                recaps = tr_children_data[-1].a['href'] # get link to recaps\n",
    "            else:\n",
    "                recaps = \"No recaps\"\n",
    "                # logger.info(\"No recaps found for %s\", comp_name)\n",
    "\n",
    "            # create Competition obj with placeholder for scores_by_group\n",
    "            comp_data = Competition(comp_name, date, scores, recaps, [], {})\n",
    "            comps.append(comp_data)\n",
    "    return comps\n",
    "\n",
    "def get_groups_scores(comp_obj:Competition) -> tuple:\n",
    "    \"\"\" parses page with scores.\n",
    "        Returns a tuple that contains a list of Groups and a dictionary of scores_by_group\n",
    "    \"\"\"\n",
    "    scores_page = comp_obj.scores # url for scores page\n",
    "    if \"https://\" not in comp_obj.scores : # == \"No scores\"\n",
    "        scores_by_group = {\"No groups participated in this competition\": \"No scores to report\"}\n",
    "    else:\n",
    "        html_data = check_cache(scores_page)\n",
    "\n",
    "        soup = bs(html_data, 'html.parser')\n",
    "        # logger.info(\"Parsing page: %s\", scores_page)\n",
    "\n",
    "        groups_list = [] # list of Group objects\n",
    "        scores_by_group = {}\n",
    "\n",
    "        scores_div = soup.find_all('div', attrs={'class': 'table-responsive'}) # list of divs\n",
    "        scores_table = scores_div[0].table\n",
    "        table_rows = scores_table.find_all('tr')\n",
    "\n",
    "        for row in table_rows:\n",
    "            tcells = list(row.children)\n",
    "            if len(tcells) == 3: # rows with class levels\n",
    "                class_level = tcells[1].b.contents[0] # group class_level\n",
    "            elif len(tcells) == 4: # rows with group names\n",
    "                em = tcells[2].contents[1]\n",
    "                group_name = tcells[2].contents[0].strip() # group names\n",
    "                location = em.contents[0].replace('(', '').replace(')', '') # group location\n",
    "\n",
    "                score = tcells[-1].b.contents[0]\n",
    "\n",
    "                group_data = Group(group_name, class_level, location, [])\n",
    "                groups_list.append(group_data)\n",
    "\n",
    "                scores_by_group[group_data.name] = score\n",
    "\n",
    "        return groups_list, scores_by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(\n",
    "#     format='%(levelname)s: %(message)s',\n",
    "#     level=logging.DEBUG\n",
    "# )\n",
    "\n",
    "# Create logger\n",
    "# logger = logging.getLogger()\n",
    "\n",
    "# Create logger filename and path\n",
    "LOGPATH = \"./wgi_score_parser_log.log\"\n",
    "\n",
    "# Add logger file and stream handlers\n",
    "# logger.addHandler(logging.FileHandler(LOGPATH)) # write log to file\n",
    "# logger.addHandler(logging.StreamHandler(sys.stdout)) # stream log to stdout\n",
    "\n",
    "# Start logger\n",
    "start_date_time = dt.datetime.now()\n",
    "# logger.info(f\"Start run: {start_date_time.isoformat()}\")\n",
    "# logger.info(\"Start run: %s\", start_date_time.isoformat()) # log start time\n",
    "\n",
    "\n",
    "all_competitions = [] # store competition objects\n",
    "all_groups = [] # store group objects\n",
    "\n",
    "comps_to_write = [] # competitions to write\n",
    "groups_to_write = [] # groups to write\n",
    "\n",
    "\n",
    "for link in read_json(URLS):\n",
    "    # check_cache(link)\n",
    "    # get_competitions\n",
    "    competitions = get_competitions(link)\n",
    "\n",
    "    # get groups and score data for each competition\n",
    "    for comp in competitions:\n",
    "        groups_and_scores = get_groups_scores(comp)\n",
    "\n",
    "        if isinstance(groups_and_scores, tuple):\n",
    "            groups, scores = groups_and_scores\n",
    "            comp.groups = groups # update Competition class obj with groups list\n",
    "            comp.scores_by_group = scores # update Competition class obj with scores dict\n",
    "\n",
    "            if len(groups) > 1:\n",
    "                for group in groups:\n",
    "                    all_groups.append(group)\n",
    "\n",
    "        all_competitions.append(comp)\n",
    "\n",
    "        comps_to_write.append(comp.jsonify())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for group in all_groups:\n",
    "    # dict of comps and scores\n",
    "    group_comps = {}\n",
    "    for comp in all_competitions:\n",
    "        if group in comp.groups:\n",
    "            group_comps[f\"{comp.title}, {comp.date}\"] = comp.scores_by_group.get(group.name) # get score for that group\n",
    "    group.competitions = group_comps\n",
    "\n",
    "    groups_to_write.append(group.jsonify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4082\n",
      "946\n",
      "[{'name': '4th Wall', 'class_level': 'Independent Marching World', 'location': 'Louisville, Ky', 'competitions': {'Dayton Perc Finals, March 27, 2022': '81.500', 'Dayton Perc Prelims, March 26, 2022': '78.400', 'Indianapolis Perc Finals, March 06, 2022': '75.600', 'Indianapolis Perc Prelims, March 05, 2022': '75.850'}}, {'name': 'A.L. Brown HS', 'class_level': 'Scholastic Marching A', 'location': ' Kannapolis, North Carolina', 'competitions': {'PSA Prelims, April 19, 2018': '82.150'}}, {'name': 'Acadiana HS', 'class_level': 'Scholastic Marching A', 'location': 'Lafayette, Louisiana', 'competitions': {'PSA Prelims, April 19, 2018': '0.000', 'South Power Regional Perc Prelims, March 17, 2018': '74.600'}}, {'name': 'Aftermath Percussion', 'class_level': 'Independent Marching A', 'location': ' Lehigh Valley, Pennsylvania', 'competitions': {'PIA Prelims, April 19, 2018': '76.588'}}, {'name': 'Albemarle County Combined Schools', 'class_level': 'Scholastic Marching A', 'location': 'Charlottesville, VA', 'competitions': {'Richmond Perc Finals, March 05, 2022': '65.300', 'Richmond Perc Prelims, March 05, 2022': '63.800'}}, {'name': 'Alchemy Percussion presented by Carolina Gold', 'class_level': 'Independent Marching Open', 'location': ' Raleigh, North Carolina', 'competitions': {'PIO Prelims Hobart Arena, April 11, 2019': '80.150', 'Atlanta Perc Prelims, March 16, 2019': '75.750', 'Atlanta Perc Finals, March 16, 2019': '78.650', 'Richmond Perc Finals, February 23, 2019': '72.350', 'Richmond Perc Prelims, February 23, 2019': '69.450', 'PIO Prelims, April 19, 2018': '82.475'}}, {'name': 'Alpharetta HS', 'class_level': 'Scholastic Marching A', 'location': 'Alpharetta, GA', 'competitions': {'Atlanta Perc Finals, March 19, 2022': '82.050', 'Atlanta Perc Prelims, March 19, 2022': '79.650'}}, {'name': 'Amador Valley HS', 'class_level': 'Scholastic Marching Open', 'location': 'Pleasanton, CA', 'competitions': {'West Perc Finals, March 24, 2019': '78.575', 'West Perc Prelims, March 23, 2019': '79.550'}}, {'name': 'Amador Valley HS', 'class_level': 'Scholastic Marching World', 'location': 'Pleasanton, CA', 'competitions': {'San Bernardino Perc Finals, March 27, 2022': '82.950', 'San Bernardino Perc Prelims, March 26, 2022': '81.450'}}, {'name': 'Ancient City Ensemble', 'class_level': 'Independent Marching Open', 'location': ' Trenton, Florida', 'competitions': {'Orlando Perc Prelims, February 22, 2020': '76.900', 'Orlando Perc Finals, February 22, 2020': '78.950', 'Open Class Finals UD Arena, April 13, 2019': '91.163', 'PIO Semi Finals Nutter Center, April 12, 2019': '91.200', 'Orlando Perc Prelims, February 23, 2019': '78.450', 'Orlando Perc Finals, February 23, 2019': '80.550', 'PIO Prelims Hobart Arena, April 11, 2019': '91.400', 'PIO Semi Finals, April 20, 2018': '84.925', 'PIO Prelims, April 19, 2018': '84.325'}}, {'name': 'Angola HS', 'class_level': 'Scholastic Marching A', 'location': 'Angola, IN', 'competitions': {'Chicago Perc Finals, February 15, 2020': '61.400', 'Chicago Perc Prelims, February 15, 2020': '63.350'}}, {'name': 'Apex Indoor Percussion', 'class_level': 'Independent Marching Open', 'location': 'Farmington Hills, MI', 'competitions': {'Troy Perc Finals, February 08, 2020': '71.325', 'Troy Perc Prelims, February 08, 2020': '70.450'}}, {'name': 'Appoquinimink HS', 'class_level': 'Scholastic Marching A', 'location': 'Middletown, DE', 'competitions': {'Monroe Township Perc Prelims, March 26, 2022': '81.525', 'Monroe Township Perc Finals, March 26, 2022': '79.250'}}, {'name': 'Arapahoe HS', 'class_level': 'Scholastic Concert Open', 'location': 'Centennial, CO', 'competitions': {'Denver Perc Finals, March 12, 2022': '79.200', 'Denver Perc Prelims, March 12, 2022': '75.300', 'Denver Perc Finals, March 07, 2020': '84.550', 'Denver Perc Prelims, March 07, 2020': '83.900', 'Concert Finals Nutter Center, April 12, 2019': '88.050', 'Concert Prelims Nutter Center, April 11, 2019': '88.525', 'Denver Perc Prelims, March 09, 2019': '82.600', 'Denver Perc Finals, March 09, 2019': '83.000'}}, {'name': 'Arbor View HS', 'class_level': 'Scholastic Marching A', 'location': 'Las Vegas, NV', 'competitions': {'San Bernardino Perc Finals, March 27, 2022': '87.600', 'San Bernardino Perc Prelims, March 26, 2022': '84.950', 'Phoenix Perc Finals, March 12, 2022': '82.500', 'Phoenix Perc Prelims, March 12, 2022': '78.650', 'Temecula Perc Finals, February 23, 2020': '77.850', 'Temecula Perc Prelims, February 22, 2020': '76.450', 'West Perc Finals, March 24, 2019': '82.600', 'West Perc Prelims Grand Terrace, March 23, 2019': '80.550', 'Temecula Perc Finals, February 24, 2019': '71.200', 'Temecula Perc Prelims, February 23, 2019': '70.650'}}, {'name': 'Arcadia HS', 'class_level': 'Scholastic Marching A', 'location': 'Arcadia, California', 'competitions': {'Phoenix Perc Prelims, March 09, 2019': '80.400', 'Phoenix Perc Finals, March 09, 2019': '80.750'}}, {'name': 'Arcadia HS', 'class_level': 'Scholastic Marching Open', 'location': ' Arcadia, California', 'competitions': {'San Bernardino Perc Prelims, March 26, 2022': '90.850', 'Open Class Finals UD Arena, April 13, 2019': '89.575', 'West Perc Finals, March 24, 2019': '92.700', 'West Perc Prelims, March 23, 2019': '92.100', 'Temecula Perc Finals, February 24, 2019': '77.850', 'Temecula Perc Prelims, February 23, 2019': '76.350', 'Open Class Finals, April 21, 2018': '86.713', 'PSO Semi Finals Nutter Center, April 12, 2019': '89.788', 'PSO Prelims BB and T Arena, April 11, 2019': '90.800', 'PSO Semi Finals, April 20, 2018': '88.588', 'PSO Prelims, April 19, 2018': '89.300'}}, {'name': 'Arcadia HS', 'class_level': 'Scholastic Marching World', 'location': ' Arcadia, California', 'competitions': {'PSW Prelims, April 21, 2022': '94.888', 'San Bernardino Perc Finals, March 27, 2022': '92.250', 'San Bernardino Perc Prelims, March 26, 2022': '90.850', 'World Class Finals UD Arena, April 13, 2019': '97.338', 'PSW Semi Finals UD Arena, April 12, 2019': '95.875', 'West Perc Finals, March 24, 2019': '92.700', 'West Perc Prelims, March 23, 2019': '92.100', 'World Class Finals, April 21, 2018': '96.338', 'PSW Semi Finals, April 20, 2018': '95.063', 'PSW Prelims UD Arena, April 11, 2019': '94.775', 'PSW Prelims, April 19, 2018': '93.225'}}, {'name': 'Ardrey Kell HS', 'class_level': 'Scholastic A Winds', 'location': 'Charlotte, NC', 'competitions': {'Richmond Winds Prelims, February 29, 2020': '77.700', 'Richmond Winds Finals, February 29, 2020': '79.050', 'Winds Finals UD Arena, April 14, 2019': '93.600', 'Winds Prelims Nutter Center, April 13, 2019': '92.475', 'Atlanta Winds Prelims, March 16, 2019': '81.750', 'Atlanta Winds Finals, March 16, 2019': '83.250'}}, {'name': 'Ardrey Kell HS', 'class_level': 'Scholastic Marching A', 'location': 'Charlotte, NC', 'competitions': {'Atlanta Perc Prelims, March 16, 2019': '84.200', 'Atlanta Perc Finals, March 16, 2019': '84.650'}}]\n",
      "946\n"
     ]
    }
   ],
   "source": [
    "groups_to_clean = sorted(groups_to_write, key=lambda x: (x['name'], x['class_level']))\n",
    "\n",
    "clean_groups = []\n",
    "done_cleaning = []\n",
    "\n",
    "# find duplicate group entries, combine competitions, normalize locations\n",
    "for i, group in enumerate(groups_to_clean):\n",
    "    if len(clean_groups) == 0:\n",
    "        clean_groups.append(group)\n",
    "    elif group['name'] == clean_groups[-1]['name'] and group['class_level'] == clean_groups[-1]['class_level']:\n",
    "        if clean_groups[-1]['competitions'] != group['competitions']:\n",
    "            clean_groups[-1]['competitions'] |= group['competitions']\n",
    "            if clean_groups[-1] not in done_cleaning:\n",
    "                done_cleaning.append(clean_groups[-1])\n",
    "    else:\n",
    "        clean_groups.append(group)\n",
    "        if clean_groups[-1] not in done_cleaning:\n",
    "            done_cleaning.append(clean_groups[-1])\n",
    "\n",
    "print(len(groups_to_clean))\n",
    "print(len(clean_groups))\n",
    "print(clean_groups[:20])\n",
    "print(len(done_cleaning))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb090b1801519df74d461290f6a3ad7983a75dcf94711c681fabb2ead4c463ab"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
